{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jack-of-all-trades-22/ARQe/blob/main/AI_Enhanced_Product_Photoshoot_Visuals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement \"AI-Enhanced Product Photoshoot Visuals and Filter\""
      ],
      "metadata": {
        "id": "6TJkuHYKarcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_cv"
      ],
      "metadata": {
        "id": "a2FoFeVKxatn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras_cv.models import StableDiffusion\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Cm8jFPjXl4RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Stable Diffusion model\n",
        "model_diffusion = StableDiffusion(img_width=512, img_height=512)"
      ],
      "metadata": {
        "id": "YhZAekJIn1IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained MobileNetV2 model for image classification\n",
        "model_classification = tf.keras.applications.MobileNetV2(weights='imagenet')"
      ],
      "metadata": {
        "id": "eCL_-v5Tn29F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(prompt, batch_size=3):\n",
        "    # Generate images based on the prompt\n",
        "    images = model_diffusion.text_to_image(prompt, batch_size=batch_size)\n",
        "    return images\n"
      ],
      "metadata": {
        "id": "i8Bfu0EDzP7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(images):\n",
        "    # Plot the generated images\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i, image in enumerate(images):\n",
        "        ax = plt.subplot(1, len(images), i + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "abgatRkcoAsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(images):\n",
        "    # Resize images to match the input shape expected by MobileNetV2 (224x224)\n",
        "    resized_images = [tf.image.resize(img, (224, 224)) for img in images]\n",
        "    # Preprocess images for MobileNetV2\n",
        "    preprocessed_images = [tf.keras.applications.mobilenet_v2.preprocess_input(img) for img in resized_images]\n",
        "    preprocessed_images = np.array(preprocessed_images)\n",
        "    return preprocessed_images"
      ],
      "metadata": {
        "id": "uCBde93eoGzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_images(images, model):\n",
        "    # Preprocess and resize images\n",
        "    preprocessed_images = preprocess_images(images)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(preprocessed_images)\n",
        "\n",
        "    # Decode predictions\n",
        "    decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions)\n",
        "\n",
        "    return decoded_predictions"
      ],
      "metadata": {
        "id": "6dKfqn-LoKir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_non_relevant_images(images, model):\n",
        "    # Implement a binary classifier for demonstration\n",
        "\n",
        "    relevant_images = []\n",
        "    for image in images:\n",
        "        # Use the MobileNetV2 model for binary classification\n",
        "        preprocessed_image = preprocess_images([image])\n",
        "        prediction = model.predict(preprocessed_image)\n",
        "\n",
        "        # Modify this condition based on your binary classification model\n",
        "        if prediction[0][0] > 0.5:\n",
        "            relevant_images.append(image)\n",
        "\n",
        "    return relevant_images"
      ],
      "metadata": {
        "id": "PIMswVq02dEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "prompt = \"Car\"\n",
        "batch_size = 3"
      ],
      "metadata": {
        "id": "Qk-J10SDoNO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and plot images\n",
        "generated_images = generate_images(prompt, batch_size=batch_size)\n",
        "relevant_images = filter_non_relevant_images(generated_images, model_classification)\n",
        "plot_images(generated_images)"
      ],
      "metadata": {
        "id": "dWsxdlscoQvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify generated images\n",
        "classifications = classify_images(generated_images, model_classification)"
      ],
      "metadata": {
        "id": "Vo2wRgB4oU0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the classifications\n",
        "for i, img_class in enumerate(classifications):\n",
        "    print(f\"Image {i + 1} classification:\")\n",
        "    for j, (imagenet_id, label, score) in enumerate(img_class):\n",
        "        print(f\"{j + 1}: {label} ({score:.2f})\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "tjBgwdFaoXUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oinZ_K1q8nXj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}